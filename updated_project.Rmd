---
Author: "Juan D Astudillo" 
title: "Term Project 390.4- 2019"
output: html_document
---

## R Markdown

```{r}
pacman::p_load(dplyr, tidyr, ggplot2, magrittr, stringr, mlr)
housing_data = read.csv("housing_data_2016_2017.csv")

```

##Delete variables that we dont need
```{r}
housing_data %<>%
  select(-c(HITId, HITTypeId, Title, Description, Keywords, Reward, CreationTime, MaxAssignments,	RequesterAnnotation,	AssignmentDurationInSeconds,	AutoApprovalDelayInSeconds,	Expiration,	NumberOfSimilarHITs, LifetimeInSeconds,	AssignmentId,	WorkerId,	AssignmentStatus,	AcceptTime,	SubmitTime,	AutoApprovalTime,	ApprovalTime,	RejectionTime,	RequesterFeedback,	WorkTimeInSeconds, LifetimeApprovalRate,	Last30DaysApprovalRate,	Last7DaysApprovalRate, URL, url, date_of_sale))
```
## Clean Data
```{r}
housing_data %<>%
  mutate( zip_code = str_extract(full_address_or_zip_code, "[0-9]{5}")) 

housing_data %<>%
  mutate(co_op = ifelse(substr(housing_data$coop_condo, 1, 5) == "co-op", 1, 0)) %>%
  mutate(condo = ifelse(substr(housing_data$coop_condo, 1, 5) == "condo", 1, 0)) %>%
  mutate(dogs_allowed = ifelse(substr(housing_data$dogs_allowed, 1, 3) == "yes", 1, 0)) %>%
  mutate(cats_allowed = ifelse(substr(housing_data$cats_allowed, 1, 3) == "yes", 1, 0)) %>%
  mutate( pets_allowed = ifelse( cats_allowed + dogs_allowed > 0, 1, 0))


housing_data %<>%
  select(-c(dogs_allowed,cats_allowed))

d = housing_data

d %<>%
  mutate(maintenance_cost = sjmisc::rec(maintenance_cost, rec = "NA = 0 ; else = copy")) %<>%
  mutate(common_charges = sjmisc::rec(common_charges, rec = "NA = 0 ; else = copy"))##recode from NA to 0.


# combine maintaince cost and common charges
d %<>% 
  mutate( monthly_cost = common_charges + maintenance_cost)

d %<>%
  mutate(monthly_cost = sjmisc::rec(monthly_cost, rec = "0 = NA ; else = copy"))

## Garage exists conver it to binary

d %<>%
  mutate(garage_exists = sjmisc::rec(garage_exists, rec = "NA = 0 ; else = copy")) ##recode from NA to 0. 

d %<>%
  mutate(garage_exists = sjmisc::rec(garage_exists, rec = " eys = 1; UG = 1 ; Underground = 1; yes = 1 ; Yes = 1 ; else = copy")) ##recode from NA to 0.

d %<>%
  select(-c(maintenance_cost , common_charges, model_type , coop_condo))

```

##Change variable type 
```{r}
d %<>%
  mutate( zip_code = as.factor(zip_code))%>%
  mutate( dining_room_type = as.factor(dining_room_type)) %>%
  mutate( fuel_type = as.factor(fuel_type)) %>%
  mutate( garage_exists = as.factor(garage_exists)) %>%
  mutate( num_bedrooms = factor(num_bedrooms, ordered = TRUE)) %>%
  mutate( num_half_bathrooms = factor(num_half_bathrooms, ordered = TRUE))%>%
  mutate( num_full_bathrooms = factor(num_full_bathrooms, ordered = TRUE))%>%
  mutate( num_total_rooms = factor(num_total_rooms, ordered = TRUE))%>%
  mutate( num_floors_in_building = factor(num_floors_in_building, ordered = TRUE)) %>%
  mutate( kitchen_type = as.factor(kitchen_type)) %>%
  mutate( parking_charges = as.numeric(parking_charges)) %>%
  mutate( listing_price_to_nearest_1000 = as.numeric(listing_price_to_nearest_1000)) 
```

We are trying to predict `sale_price`. So let's section our dataset:

```{r}
y = d$sale_price
X = d


X$full_address_or_zip_code = NULL
table(housing_data$listing_price_to_nearest_1000)


##Since we have zip code with too many factors we have to splid the data
X %<>%
  mutate(zip_code = as.character(zip_code))%<>%
  mutate(zip_code = as.numeric(zip_code))


X1 = X %>%
  filter(zip_code > 11365)  

X2 = X %>%
  filter(zip_code < 11366)

X1 = X1 %<>%
  mutate(zip_code = factor(zip_code))

X2 = X2 %<>%
  mutate(zip_code = factor(zip_code))

```

Let's first create a matrix with $p$ columns that represents missingness

```{r}
##X1
M = tbl_df(apply(is.na(X), 2, as.numeric))
colnames(M) = paste("is_missing_", colnames(X), sep = "")
head(M)
summary(M)

```

Some of these missing indicators are collinear because they share all the rows they are missing on. Let's filter those out:

```{r}
M = tbl_df(t(unique(t(M))))
```


Some featuers did not have missingness so let's remove them:

```{r}
M %<>% select_if(function(x){sum(x) > 0})
head(M)
dim(M)
colSums(M)

```

Now let's impute using the package. we cannot fit RF models to the entire dataset (it's 26,000! observations) so we will sample 5 for X1 and  for each of the trees and then average. That will be good enough.

```{r}
pacman::p_load(missForest)
X1imp = missForest(data.frame(X1), sampsize = rep(100, ncol(X1)))$ximp
X2imp = missForest(data.frame(X2), sampsize = rep(60, ncol(X2)))$ximp

```

```{r}
XimpTotal = as.data.frame(rbind(X1imp, X2imp))
str(X2)
```

```{r}
Xnew = data.frame(cbind(XimpTotal, M))
linear_mod_impute_and_missing_dummies = lm(Xnew$sale_price ~ ., Xnew)
summary(linear_mod_impute_and_missing_dummies)

```


### REMOVING MISSING Y SECTION
```{r}
finalproject = Xnew

pacman::p_load(ggmap)

finalproject = cbind(finalproject, d$full_address_or_zip_code)

finalproject %<>%
  mutate(address = d$full_address_or_zip_code) %>%
  select(-d$full_address_or_zip_code`)

finalproject %<>%
  mutate(address = as.character(address))

finalproject %<>%
  mutate(lat = geocode(full_address_or_zip_code)$lat, lon = geocode(full_address_or_zip_code)$lon )

finalproject %<>%
  filter(is_missing_sale_price == 0)
```

## VALIDATION
```{r}
pacman::p_load(mlr)
```

```{r}
set.seed(1989)

modeling_task = makeRegrTask(data = finalproject, target = "sale_price") #instantiate the task
algorithm = makeLearner("regr.randomForest") #instantiate the OLS learner algorithm on the diamonds dataset and set y = price
validation = makeResampleDesc("CV", iters = 5) #instantiate the 5-fold CV
resample(algorithm, modeling_task, validation) #execute



```

```{r}
modeling_task = makeRegrTask(data = finalproject, target = "sale_price") #instantiate the task
res = resample(algorithm, modeling_task, validation, measures = list(rmse)) #execute
res
mean(res$measures.test$rmse)
sd(res$measures.test$rmse)

```
 
 
```{r}
#REGRESSION TREE
pacman::p_load(tree)

train = sample(1 : nrow(finalproject), nrow(finalproject)*4/5)
test = - train
trainig_data = finalproject[train, ]
testing_data = finalproject[train, ]


```
 
